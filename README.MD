# GraphyDocs Project Report

GraphyDocs is a code analysis tool built with Python and TypeScript/React that generates graph-based representations of codebases. The project aims to create a language-agnostic system using Language Server Protocol (LSP) to build abstract code representations, ultimately intended for LLM-based code analysis and documentation.

The system is built around a Python backend(FastAPI) that implements LSP client interfaces and graph algorithms, paired with a React/TypeScript frontend using ForceGraph for the graph visualization. Data storage is handled by Neo4j for graph relationships, Postgress for Projects and Session handling and Redis integration prepared for future caching optimizations. The system employs an asynchronous WebSocket architecture for real-time updates. Every service is contained in a docker container and orchestrated using docker compose to ease an eventual depolyment.

While my initial idea was to focus on the development of the algorithm that performed the graph mapping algorithm, but since I wanted to be able to see the whole graph creation process, I spent time creating a scalable system that separated the codebase analysis from other opertaions like caching, saving to db and sending updating the client with the new graph. To do the last step, since, as I already said I wanted the client to be able to see live the nodes and edges being created I created a websocket that is able to send updates whenever an analysis was running. Furhtermore I wanted 

One of the most significant challenges was managing analysis state and session handling. The system needed to handle multiple scenarios: starting new analyses, connecting to ongoing analyses, and retrieving partially created graphs. This complexity required careful state management and robust WebSocket implementation. The project implements a generalized LSP interface that allows straightforward extension to new relationship types, making future expansions more manageable.

The asynchronous architecture proved crucial for handling LSP and database latency effectively. While a pooling manager was initially considered for performance optimization, this feature was deprioritized to focus on core algorithm development. Redis infrastructure is in place but not yet utilized, providing opportunity for future performance improvements through caching.

The project successfully processes Python codebases and establishes a solid foundation for future LLM integration, though larger graph visualizations require additional optimization work. The modular design ensures that new LSP-based relationships can be easily added to enhance the graph's representation of code structure.